#!/usr/bin/php
<?php
// Taken from https://github.com/mparker1001/githubstats. Please see associated README for instructions on how to use this script.

// Check and set arguments. If they do not exist, then stop the script
if (@$argv[1] == "" || @$argv[2] == "" || @$argv[3] == "") {
  die("Usage: ./githubstats <user_name> <org_name> <start_date_in_YYYYMMDDHHMM>\n");
}
else {
  $username = $argv[1];
  $organization = $argv[2];
  $start_date = $argv[3];
}

// Set cache filenames
$orgcachefile = "orgdata.cache";

// Set cache expire time - 1 hour by default
$cache_expire_time = "3600";

// Get API token and set timezone from environment variables
$token = getenv('GITHUB_TOKEN');
date_default_timezone_set(getenv('GITHUB_TIMEZONE'));

// Initialize boolen which will be used to control looping through paged results
$has_more = false;

// Be sure the arrays containing the API data are cleared before running
unset($orgdata);
unset($temporgdata);
$orgdata=array();
$temporgdata=array();

// Declare get headers from curl response function
function get_headers_from_curl_response($response)
{
    $headers = array();
    $header_text = substr($response, 0, strpos($response, "\r\n\r\n"));

    foreach (explode("\r\n", $header_text) as $i => $line)
        if ($i === 0)
            $headers['http_code'] = $line;
        else
        {
            list ($key, $value) = explode(': ', $line);
            $headers[$key] = $value;
        }
    return $headers;
}


/* --- Get repos from organization --- */

// Check if an org cache file exists and is not expired
if ( (time() - @filemtime($orgcachefile)) > $cache_expire_time ) {
  // If the cache file does not exist or is expired, get the org data from the API
  @unlink($orgcachefile);
  do {

  // Set endpoint based on org name if this is the first run
  if ( $has_more == false ) {
    $endpoint = "https://api.github.com/orgs/$organization/repos";
  }

  // Set cURL options
  $ch = curl_init();
  curl_setopt($ch,CURLOPT_URL, $endpoint);
  curl_setopt($ch,CURLOPT_HEADER, true);
  curl_setopt($ch,CURLOPT_RETURNTRANSFER, true);
  curl_setopt($ch,CURLOPT_HTTPHEADER, array("Authorization: token $token", "User-Agent: PHP"));

  // Post the curl command and save the resulting data set
  $result = curl_exec($ch);
  $header_size = curl_getinfo($ch, CURLINFO_HEADER_SIZE);
  $headers = get_headers_from_curl_response(substr($result, 0, $header_size));
  $temporgdata = json_decode(substr($result, $header_size));
  $orgdata = array_merge($orgdata, $temporgdata);

  // Determine if this is the last page of the data
  $link = explode(" ", $headers['Link']);
  if ( strpos($link[1],"next") != false ) {
    $has_more = true;
    $endpoint = str_replace(array("<",">",";",), "" ,$link[0]);
  }
  else {
    $has_more = false;
  }

  } while ( $has_more == true );

  // After looping through all the pages, save the org data to a cache file
  file_put_contents($orgcachefile, json_encode($orgdata));

}
else {
  // If the cache file is not expired, import the org data from the cache file
  $orgdata = json_decode(file_get_contents($orgcachefile), true);
}

print_r($orgdata);

?>
